# DEVA â€” Multimodal Sentiment Analysis on MELD

> Transformer audio & vision into textual descriptions for unified multimodal sentiment prediction.

---

Lien du dataset : https://www.kaggle.com/datasets/argish/meld-preprocessed/data


> ğŸ­ **Texte + Audio + Vision** unifiÃ©s pour prÃ©dire le sentiment humain avec lâ€™architecture DEVANet.

---

## ğŸš€ Introduction
Ce projet implÃ©mente **DEVANet**, un modÃ¨le multimodal combinant :
- ğŸ“ **Texte** (BERT + Transformer)
- ğŸ”Š **Audio** (features & Mel-spectrograms)
- ğŸ‘€ **Vision** (Ã©motions faciales)

Objectif ğŸ¯ : prÃ©dire le sentiment **positive / negative / neutral** pour chaque utterance du dataset **MELD**.

Lâ€™architecture repose sur :
- un encodeur texte avancÃ©,
- des encodeurs audio & visuels simplifiÃ©s,
- une **Cross-Modal Attention**,
- une **Multimodal Fusion Unit (MFU)** apprenant Ã  pondÃ©rer les modalitÃ©s,
- un prÃ©dicteur final donnant un score continu âˆˆ [-1, 1].

---

## ğŸ“š Dataset MELD

### ğŸ“ Structure des fichiers `.pt`
Chaque entrÃ©e contient :
- ğŸ—£ï¸ `utterance` â€” texte  
- ğŸ­ `emotion` â€” Ã©motion MELD  
- ğŸ§ `audio` â€” vecteur audio brut  
- ğŸ”‰ `audio_mel` â€” Mel-spectrogram  
- ğŸ‘¤ `face` â€” features faciales  

---

### ğŸ”„ Mapping Ã©motions â†’ sentiment
| Emotion | Sentiment |
|---------|-----------|
| joy, surprise | ğŸ˜Š positive |
| sadness, anger, fear, disgust | ğŸ˜¡ negative |
| neutral | ğŸ˜ neutral |

---

### ğŸ“Š DonnÃ©es Ã©chantillonnÃ©es (stratified)
| Set | Total | ğŸ˜€ Pos | ğŸ˜¡ Neg | ğŸ˜ Neu |
|------|-------|--------|--------|--------|
| Train | 300 | 100 | 100 | 100 |
| Dev | 150 | 50 | 50 | 50 |
| Test | 150 | 50 | 50 | 50 |

Toutes les modalitÃ©s sont disponibles pour 100% des Ã©chantillons.

---

## ğŸ§  Architecture DEVANet

### ğŸ“ 1. Encodeur Texte  
- BERT tokenizer + BERT embeddings  
- Transformer Encoder  
- Token spÃ©cial **Em** pour booster la reprÃ©sentation globale  

---

### ğŸ§ 2. AudioDescriptionGenerator  
Transforme les Mel-features en embedding 768D :  
- Projection linÃ©aire  
- AdaptiveAvgPool1d  
- MLP  

---

### ğŸ‘€ 3. VisionDescriptionGenerator  
Encode lâ€™Ã©motion en un embedding dense 768D :  
- `nn.Embedding(num_emotions â†’ 768)`

---

### ğŸ” 4. Cross-Modal Attention  
Permet au texte dâ€™extraire les informations pertinentes dans :
- ğŸ”Š audio  
- ğŸ‘€ vision  

Module utilisÃ© : `nn.MultiheadAttention`

---

### ğŸŒ€ 5. MFU â€” Multimodal Fusion Unit  
Le cÅ“ur de DEVANet.  
Combine texte + audio + vision via :  
- projections linÃ©aires  
- attention croisÃ©e  
- **pondÃ©ration apprenable** :  
  - Î± = poids audio  
  - Î² = poids vision  

---

### ğŸ¯ 6. PrÃ©dicteur final  
Une MLP prÃ©dit un **score de sentiment continu** dans [-1, 1].  
Le signe du score donne la classe.

---

## ğŸ“ˆ EntraÃ®nement & Ã‰valuation

### âš™ï¸ Setup
- Optimiseur : **AdamW**  
- Loss : **MSE**  
- Nombre dâ€™Ã©poques : 10  
- Sauvegarde : `best_deva_meld.pt`  

### ğŸ“ MÃ©triques utilisÃ©es
- **Acc-2** (binaire positive / nÃ©gative)  
- **Acc-5**  
- **Acc-7**  
- **F1-score**  
- **MAE**  
- **Pearson corr**  

---

## ğŸ§ª RÃ©sultats sur Test

| Metric | Value |
|--------|--------|
| Test Loss | â­ 0.0054 |
| **Acc-2** | **0.8733** |
| Acc-5 | 0.2000 |
| Acc-7 | 0.1467 |
| **F1** | **0.8768** |
| MAE | 0.0518 |
| **Pearson** | **0.9975** |

Les rÃ©sultats montrent une excellente cohÃ©rence (corrÃ©lation â‰ˆ 1) et une trÃ¨s bonne prÃ©cision binaire.

---

## ğŸ§© MFU â€” Analyse des poids Î± & Î²

### ğŸ”¢ Poids appris
| Poids | Valeur |
|--------|---------|
| Î± (audio) | 0.9973 |
| Î² (vision) | 1.0011 |

### ğŸ§® Contribution normalisÃ©e
| ModalitÃ© | Contribution |
|-----------|--------------|
| ğŸ”Š Audio | 49.9% |
| ğŸ‘€ Vision | 50.1% |

ğŸ“Œ **Le modÃ¨le privilÃ©gie trÃ¨s lÃ©gÃ¨rement la vision (+0.2%).**

---

## ğŸ” Exemples de PrÃ©dictions

### âœ” Example 1
- **Text** : "Why do all you're coffee mugs have numbers on the bottom?"  
- **True** : positive  
- **Pred** : positive (1.015)  
- **Emotion** : surprise  

### âœ” Example 2
- **Text** : "Whereâ€™s number 27?!"  
- **True** : negative  
- **Pred** : negative (-0.842)  
- **Emotion** : anger  

### âœ” Example 3
- **Text** : "Y'know what?"  
- **True** : neutral  
- **Pred** : neutral (-0.015)  

### âœ” Examples 4 & 5  
Plusieurs utterances neutres â†’ toutes prÃ©dites correctement.

---

## â–¶ï¸ Comment ExÃ©cuter le Projet

### ğŸ“¦ PrÃ©requis
- Python 3.x  
- DonnÃ©es MELD prÃ©traitÃ©es disponibles localement  
- Librairies essentielles  

### ğŸ”§ Auteurs 
- Yohan MARCEL
- Thomas MATHIOT
- Nicolas PINIER
- Anthony SABBAGH
